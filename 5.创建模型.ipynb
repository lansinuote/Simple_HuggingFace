{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3405ef55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BertConfig {\n",
       "   \"attention_probs_dropout_prob\": 0.1,\n",
       "   \"classifier_dropout\": null,\n",
       "   \"hidden_act\": \"gelu\",\n",
       "   \"hidden_dropout_prob\": 0.1,\n",
       "   \"hidden_size\": 768,\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"intermediate_size\": 3072,\n",
       "   \"layer_norm_eps\": 1e-12,\n",
       "   \"max_position_embeddings\": 512,\n",
       "   \"model_type\": \"bert\",\n",
       "   \"num_attention_heads\": 12,\n",
       "   \"num_hidden_layers\": 4,\n",
       "   \"pad_token_id\": 0,\n",
       "   \"position_embedding_type\": \"absolute\",\n",
       "   \"transformers_version\": \"4.42.3\",\n",
       "   \"type_vocab_size\": 2,\n",
       "   \"use_cache\": true,\n",
       "   \"vocab_size\": 15000\n",
       " },\n",
       " torch.Size([4, 125, 768]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "#使用配置文件创建一个bert模型\n",
    "config = BertConfig(vocab_size=15000, num_hidden_layers=4)\n",
    "model = BertModel(config)\n",
    "\n",
    "#使用该模型进行试算,输入数据是4句话,每句话125个词\n",
    "input = {\n",
    "    'input_ids': torch.randint(100, 10000, [4, 125]),\n",
    "    'attention_mask': torch.ones(4, 125).long()\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**input)\n",
    "\n",
    "#计算结果是把这4句话向量化了\n",
    "#可以基于这些向量做各种下游任务\n",
    "config, out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9580b70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GPT2Config {\n",
       "   \"activation_function\": \"gelu_new\",\n",
       "   \"attn_pdrop\": 0.1,\n",
       "   \"bos_token_id\": 50256,\n",
       "   \"embd_pdrop\": 0.1,\n",
       "   \"eos_token_id\": 50256,\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"layer_norm_epsilon\": 1e-05,\n",
       "   \"model_type\": \"gpt2\",\n",
       "   \"n_embd\": 768,\n",
       "   \"n_head\": 12,\n",
       "   \"n_inner\": null,\n",
       "   \"n_layer\": 4,\n",
       "   \"n_positions\": 1024,\n",
       "   \"reorder_and_upcast_attn\": false,\n",
       "   \"resid_pdrop\": 0.1,\n",
       "   \"scale_attn_by_inverse_layer_idx\": false,\n",
       "   \"scale_attn_weights\": true,\n",
       "   \"summary_activation\": null,\n",
       "   \"summary_first_dropout\": 0.1,\n",
       "   \"summary_proj_to_labels\": true,\n",
       "   \"summary_type\": \"cls_index\",\n",
       "   \"summary_use_proj\": true,\n",
       "   \"transformers_version\": \"4.42.3\",\n",
       "   \"use_cache\": true,\n",
       "   \"vocab_size\": 15000\n",
       " },\n",
       " torch.Size([4, 125, 768]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2Model\n",
    "\n",
    "#使用配置文件创建一个gpt2模型\n",
    "config = GPT2Config(vocab_size=15000, n_layer=4)\n",
    "model = GPT2Model(config)\n",
    "\n",
    "#执行试算\n",
    "with torch.no_grad():\n",
    "    out = model(**input)\n",
    "\n",
    "config, out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8331126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BertConfig {\n",
       "   \"attention_probs_dropout_prob\": 0.1,\n",
       "   \"classifier_dropout\": null,\n",
       "   \"hidden_act\": \"gelu\",\n",
       "   \"hidden_dropout_prob\": 0.1,\n",
       "   \"hidden_size\": 768,\n",
       "   \"id2label\": {\n",
       "     \"0\": \"LABEL_0\",\n",
       "     \"1\": \"LABEL_1\",\n",
       "     \"2\": \"LABEL_2\"\n",
       "   },\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"intermediate_size\": 3072,\n",
       "   \"label2id\": {\n",
       "     \"LABEL_0\": 0,\n",
       "     \"LABEL_1\": 1,\n",
       "     \"LABEL_2\": 2\n",
       "   },\n",
       "   \"layer_norm_eps\": 1e-12,\n",
       "   \"max_position_embeddings\": 512,\n",
       "   \"model_type\": \"bert\",\n",
       "   \"num_attention_heads\": 12,\n",
       "   \"num_hidden_layers\": 4,\n",
       "   \"pad_token_id\": 0,\n",
       "   \"position_embedding_type\": \"absolute\",\n",
       "   \"problem_type\": \"single_label_classification\",\n",
       "   \"transformers_version\": \"4.42.3\",\n",
       "   \"type_vocab_size\": 2,\n",
       "   \"use_cache\": true,\n",
       "   \"vocab_size\": 15000\n",
       " },\n",
       " tensor(1.1823),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "#直接创建一个语句分类模型\n",
    "config = BertConfig(vocab_size=15000, num_hidden_layers=4, num_labels=3)\n",
    "model = BertForSequenceClassification(config)\n",
    "\n",
    "#执行试算,参数中包括labels,可以直接计算loss\n",
    "input_with_labels = {\n",
    "    'input_ids': torch.randint(100, 10000, [4, 125]),\n",
    "    'attention_mask': torch.ones(4, 125).long(),\n",
    "    'labels': torch.ones(4).long()\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**input_with_labels)\n",
    "\n",
    "config, out.loss, out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fae710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 125, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "#可用的模型:https://huggingface.co/models\n",
    "\n",
    "#在线加载一个预训练模型\n",
    "model = AutoModel.from_pretrained('google-bert/bert-base-chinese')\n",
    "\n",
    "#执行试算\n",
    "with torch.no_grad():\n",
    "    out = model(**input)\n",
    "\n",
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005149ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-02 14:20:45,679] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "#保存一个模型到本地磁盘\n",
    "model.save_pretrained('model/google-bert/bert-base-chinese')\n",
    "\n",
    "#从本地磁盘加载模型\n",
    "model = AutoModel.from_pretrained('model/google-bert/bert-base-chinese')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
